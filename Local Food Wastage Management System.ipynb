{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1J_Exy9jSmAwdiAiBLfV7F2zSbkaUuWAk","timestamp":1755456521703}],"collapsed_sections":["vncDsAP0Gaoa","FJNUwmbgGyua","w6K7xa23Elo4","yQaldy8SH6Dl","mDgbUHAGgjLW","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    -  **Local Food Wastage Management System**\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - EDA\n","##### **Contribution**    - Individual\n","##### **Team Member 1 -**  Adarsha Kumar Karna\n"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["\n","**Project Summary: Local Food Wastage Management System**\n","\n","The Local Food Wastage Management System project was initiated to address the critical, dual-sided issue of food surplus and food insecurity. The primary objective was to develop a data-driven platform where individuals and restaurants can list excess food, and local NGOs or those in need can claim it. The project successfully navigated through a complete development lifecycle, from raw data processing and database engineering to in-depth analysis and the creation of an interactive web application.\n","\n","The technological foundation of the project was built within the versatile Python ecosystem, utilizing Google Colab as the primary development environment. The core of the data storage is a robust SQL database. While initial explorations considered a tunneled local MySQL setup, a more agile and self-contained SQLite database was ultimately implemented, proving ideal for portability and seamless integration with Colab. Data interaction was managed by the powerful SQLAlchemy library, with the pandas library serving as the backbone for all data manipulation tasks.\n","\n","A significant portion of the project was dedicated to building a resilient ETL (Extract, Transform, Load) pipeline. Raw data, provided in four separate CSV files—Providers, Receivers, Food Listings, and Claims—was first extracted into pandas DataFrames. The transformation phase was critical and involved intensive data cleaning to ensure schema consistency. This included renaming columns to match the SQL table design, combining multiple fields (e.g., 'Address' and 'City') into a single 'location' column, and selecting only relevant data for insertion. This meticulous process resolved numerous data loading errors, culminating in a rerunnable script that clears and repopulates the database, ensuring data integrity during development.\n","\n","With the database successfully populated, the project moved into an exploratory data analysis (EDA) phase to uncover actionable insights. Using SQL queries and Python's Matplotlib and Seaborn libraries, a suite of visualizations was generated. Bar charts revealed the top 10 most active food providers, the most common food items being donated, and the geographical hotspots for donations. A pie chart was created to visualize the crucial ratio of \"available\" versus \"claimed\" listings, serving as a key performance indicator for the system's effectiveness. Further analysis explored donation quantity distributions and claim activity by day of the week. A key analytical achievement was the creation of a heatmap, which cross-referenced food items with days of the week to identify patterns in when specific types of food are claimed.\n","\n","The final phase involved developing a user-facing application using Streamlit. This interactive dashboard serves as the central hub for the system. It features a sidebar with dynamic filters, allowing users to browse available food listings and narrow them down by location. The dashboard displays the key visualizations from the analysis phase, providing an at-a-glance overview of the system's activity. Crucially, the application implements the \"Create\" part of CRUD (Create, Read, Update, Delete) functionality through an intuitive web form, enabling users to add new food donations directly to the live database. This successful integration of a robust backend database with a user-friendly frontend marks the completion of a significant project milestone, laying the groundwork for full deployment and real-world impact."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here.\n","\n","https://github.com/adrs01"],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["**Write Problem Statement Here.**\n","\n","Food wastage from local restaurants and households coexists with food insecurity in the same communities. This project addresses the critical logistical gap by developing a platform to connect food donors directly with receivers in real-time, aiming to reduce waste and efficiently distribute surplus food to those in need."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Mount Google Drive**"],"metadata":{"id":"s3uD02nfZZ3e"}},{"cell_type":"code","source":["# Mount Google Drive to save your database file\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hUs1ce_-Zd45"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#***1.DATA PREPRATION AND DATABASE CREATION:-***\n","\n","**-creating table**\n","\n","**-load the datasets into pandas**\n","\n","**-data preparation/cleaning**\n","\n","**-insert data into tables**\n","\n","**-verify tables**"],"metadata":{"id":"FK5a34NnoYj4"}},{"cell_type":"markdown","source":["#**Create a Connection to a SQLite database file**"],"metadata":{"id":"srE8xVNaZ1CZ"}},{"cell_type":"code","source":["from sqlalchemy import create_engine\n","\n","db_path = '/content/drive/My Drive/Colab Notebooks/food_wastage.db'\n","engine = create_engine(f'sqlite:///{db_path}')\n","\n","try:\n","    connection = engine.connect()\n","    print(\" Successfully created/connected to the SQLite database file!\")\n","except Exception as e:\n","    print(f\" An error occurred: {e}\")\n"],"metadata":{"id":"vLD8XKHdZ575"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Creating Table**"],"metadata":{"id":"bvhpcnfsan1B"}},{"cell_type":"code","source":["# SQL statements to create the tables\n","\n","from sqlalchemy import text\n","\n","create_providers_table_sql = \"\"\"\n","CREATE TABLE IF NOT EXISTS providers (\n","    provider_id INTEGER PRIMARY KEY AUTOINCREMENT,\n","    provider_name VARCHAR(255) NOT NULL,\n","    location VARCHAR(255),\n","    contact_info VARCHAR(255)\n",");\n","\"\"\"\n","\n","create_receivers_table_sql = \"\"\"\n","CREATE TABLE IF NOT EXISTS receivers (\n","    receiver_id INTEGER PRIMARY KEY AUTOINCREMENT,\n","    receiver_name VARCHAR(255) NOT NULL,\n","    type VARCHAR(50),\n","    location VARCHAR(255)\n",");\n","\"\"\"\n","\n","create_food_listings_table_sql = \"\"\"\n","CREATE TABLE IF NOT EXISTS food_listings (\n","    listing_id INTEGER PRIMARY KEY AUTOINCREMENT,\n","    provider_id INTEGER,\n","    food_item VARCHAR(255) NOT NULL,\n","    quantity INTEGER,\n","    expiration_date DATE,\n","    status VARCHAR(50) DEFAULT 'available',\n","    FOREIGN KEY (provider_id) REFERENCES providers(provider_id)\n",");\n","\"\"\"\n","\n","create_claims_table_sql = \"\"\"\n","CREATE TABLE IF NOT EXISTS claims (\n","    claim_id INTEGER PRIMARY KEY AUTOINCREMENT,\n","    listing_id INTEGER,\n","    receiver_id INTEGER,\n","    claim_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n","    FOREIGN KEY (listing_id) REFERENCES food_listings(listing_id),\n","    FOREIGN KEY (receiver_id) REFERENCES receivers(receiver_id)\n",");\n","\"\"\"\n","\n","# --- Execute the CREATE TABLE statements ---\n","# The 'connection' object is from our previous cell\n","try:\n","    # Wrap each SQL string in the text() function\n","    connection.execute(text(create_providers_table_sql))\n","    connection.execute(text(create_receivers_table_sql))\n","    connection.execute(text(create_food_listings_table_sql))\n","    connection.execute(text(create_claims_table_sql))\n","\n","    # Commit the changes to make them permanent in the database file\n","    connection.commit()\n","\n","    print(\" All tables created successfully (if they didn't already exist).\")\n","except Exception as e:\n","    print(f\" An error occurred during table creation: {e}\")\n"],"metadata":{"id":"FwRGJda2arKX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Load the datasets into pandas**"],"metadata":{"id":"MEut7WSGcj4v"}},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","\n","providers_csv_path = '/content/drive/My Drive/Food waste management project/food waste management datasets/providers_data.csv'\n","receivers_csv_path = '/content/drive/My Drive/Food waste management project/food waste management datasets/receivers_data.csv'\n","food_listings_csv_path = '/content/drive/My Drive/Food waste management project/food waste management datasets/food_listings_data.csv'\n","claims_csv_path = '/content/drive/My Drive/Food waste management project/food waste management datasets/claims_data.csv'\n","\n","# Load CSVs into Pandas DataFrames\n","providers_df = pd.read_csv(providers_csv_path)\n","receivers_df = pd.read_csv(receivers_csv_path)\n","food_listings_df = pd.read_csv(food_listings_csv_path)\n","claims_df = pd.read_csv(claims_csv_path)\n","\n","print(\"Providers Data:\")\n","print(providers_df.head())"],"metadata":{"id":"S8mL2X8gcnjH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Data preparation cell**"],"metadata":{"id":"EJT0dU-DhMVz"}},{"cell_type":"code","source":["# --- 1. Prepare the Providers DataFrame ---\n","providers_df_renamed = providers_df.rename(columns={\n","    'Provider_ID': 'provider_id', 'Name': 'provider_name', 'Contact': 'contact_info'\n","})\n","providers_df_renamed['location'] = providers_df_renamed['Address'] + ', ' + providers_df_renamed['City']\n","providers_to_sql = providers_df_renamed[['provider_id', 'provider_name', 'location', 'contact_info']]\n","print(\" Providers DataFrame is ready.\")\n","\n","# --- 2. Prepare the Receivers DataFrame ---\n","receivers_df_renamed = receivers_df.rename(columns={\n","    'Receiver_ID': 'receiver_id', 'Name': 'receiver_name', 'Type': 'type'\n","})\n","receivers_df_renamed['location'] = receivers_df_renamed['City']\n","receivers_to_sql = receivers_df_renamed[['receiver_id', 'receiver_name', 'type', 'location']]\n","print(\" Receivers DataFrame is ready.\")\n","\n","# --- 3. Prepare the Food Listings DataFrame  ---\n","print(\"\\nOriginal Food Listings Columns:\", food_listings_df.columns)\n","food_listings_renamed = food_listings_df.rename(columns={\n","    'Food_ID': 'listing_id',\n","    'Food_Name': 'food_item',\n","    'Quantity': 'quantity',\n","    'Expiry_Date': 'expiration_date',\n","    'Provider_ID': 'provider_id'\n","})\n","# Select only the columns that exist in the 'food_listings' SQL table\n","food_listings_to_sql = food_listings_renamed[['listing_id', 'provider_id', 'food_item', 'quantity', 'expiration_date']]\n","print(\" Food Listings DataFrame is ready.\")\n","\n","\n","# --- 4. Prepare the Claims DataFrame  ---\n","print(\"\\nOriginal Claims Columns:\", claims_df.columns)\n","claims_renamed = claims_df.rename(columns={\n","    'Claim_ID': 'claim_id',\n","    'Food_ID': 'listing_id',          # Corrected column name\n","    'Receiver_ID': 'receiver_id',\n","    'Timestamp': 'claim_date'       # Corrected column name\n","})\n","# Select only the columns that exist in the 'claims' SQL table\n","claims_to_sql = claims_renamed[['claim_id', 'listing_id', 'receiver_id', 'claim_date']] # Corrected column names for selection\n","print(\" Claims DataFrame is ready.\")"],"metadata":{"id":"w64hAhWSlBmj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Insert Data into the Tables**"],"metadata":{"id":"FYdfkdccfrDm"}},{"cell_type":"code","source":["from sqlalchemy import text\n","\n","# The 'engine' object is from our first cell\n","try:\n","    # Clear all existing data from the tables first\n","    with engine.connect() as connection:\n","        connection.execute(text(\"DELETE FROM claims\"))\n","        connection.execute(text(\"DELETE FROM food_listings\"))\n","        connection.execute(text(\"DELETE FROM receivers\"))\n","        connection.execute(text(\"DELETE FROM providers\"))\n","        connection.commit()\n","    print(\" All tables cleared successfully.\")\n","\n","    # Now, insert the clean data\n","    providers_to_sql.to_sql('providers', con=engine, if_exists='append', index=False)\n","    receivers_to_sql.to_sql('receivers', con=engine, if_exists='append', index=False)\n","\n","\n","    food_listings_to_sql.to_sql('food_listings', con=engine, if_exists='append', index=False)\n","    claims_to_sql.to_sql('claims', con=engine, if_exists='append', index=False)\n","\n","    print(\" Data loaded into all tables successfully!\")\n","\n","except Exception as e:\n","    print(f\" An error occurred during data loading: {e}\")"],"metadata":{"id":"GGqFm3tKjtVH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**verify the data**"],"metadata":{"id":"thYkg9IFl_M0"}},{"cell_type":"code","source":["import pandas as pd\n","print(\"--- Verifying Data in All Tables ---\")\n","\n","try:\n","    # Query the 'providers' table\n","    providers_verify_df = pd.read_sql(\"SELECT * FROM providers LIMIT 5\", engine)\n","    print(\"\\n Top 5 rows from the 'providers' table:\")\n","    print(providers_verify_df)\n","\n","    # Query the 'receivers' table\n","    receivers_verify_df = pd.read_sql(\"SELECT * FROM receivers LIMIT 5\", engine)\n","    print(\"\\n Top 5 rows from the 'receivers' table:\")\n","    print(receivers_verify_df)\n","\n","    # Query the 'food_listings' table\n","    listings_verify_df = pd.read_sql(\"SELECT * FROM food_listings LIMIT 5\", engine)\n","    print(\"\\n Top 5 rows from the 'food_listings' table:\")\n","    print(listings_verify_df)\n","\n","    # Query the 'claims' table\n","    claims_verify_df = pd.read_sql(\"SELECT * FROM claims LIMIT 5\", engine)\n","    print(\"\\n Top 5 rows from the 'claims' table:\")\n","    print(claims_verify_df)\n","\n","except Exception as e:\n","    print(f\"\\n An error occurred while verifying the data: {e}\")"],"metadata":{"id":"f1YapreqmB8D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#***2.DATA ANALYSIS:-***"],"metadata":{"id":"UyF0RU36oGfd"}},{"cell_type":"markdown","source":["**Analysis 1: What are the most commonly donated food items?**"],"metadata":{"id":"eZRxMhGHoJyX"}},{"cell_type":"code","source":["# SQL query to count the occurrences of each food item\n","query1 = \"\"\"\n","SELECT\n","    food_item,\n","    COUNT(listing_id) AS number_of_listings\n","FROM\n","    food_listings\n","GROUP BY\n","    food_item\n","ORDER BY\n","    number_of_listings DESC\n","LIMIT 10;\n","\"\"\"\n","\n","# Execute the query and load the result into a DataFrame\n","top_foods_df = pd.read_sql(query1, engine)\n","\n","# --- Visualization ---\n","plt.figure(figsize=(12, 7))\n","sns.barplot(x='number_of_listings', y='food_item', data=top_foods_df, palette='viridis')\n","plt.title('Top 10 Most Commonly Donated Food Items')\n","plt.xlabel('Number of Listings')\n","plt.ylabel('Food Item')\n","plt.show()"],"metadata":{"id":"LmY3Lg_ZoRO8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Analysis 2: Which providers are the most active?**"],"metadata":{"id":"PdMSuwbWpnuJ"}},{"cell_type":"code","source":["# SQL query to join providers and listings, then count listings per provider\n","query2 = \"\"\"\n","SELECT\n","    p.provider_name,\n","    COUNT(fl.listing_id) AS total_listings\n","FROM\n","    providers p\n","JOIN\n","    food_listings fl ON p.provider_id = fl.provider_id\n","GROUP BY\n","    p.provider_name\n","ORDER BY\n","    total_listings DESC\n","LIMIT 10;\n","\"\"\"\n","\n","# Execute the query\n","top_providers_df = pd.read_sql(query2, engine)\n","\n","# --- Visualization ---\n","plt.figure(figsize=(12, 7))\n","sns.barplot(x='total_listings', y='provider_name', data=top_providers_df, palette='plasma')\n","plt.title('Top 10 Most Active Food Providers')\n","plt.xlabel('Total Number of Food Listings')\n","plt.ylabel('Provider Name')\n","plt.show()"],"metadata":{"id":"9vYn8ymZp0Pi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Analysis 3: Which locations have the most food listings?**"],"metadata":{"id":"4QHcMFn1p5Iq"}},{"cell_type":"code","source":["# SQL query to count listings by city/location\n","query3 = \"\"\"\n","SELECT\n","    p.location,\n","    COUNT(fl.listing_id) AS number_of_listings\n","FROM\n","    providers p\n","JOIN\n","    food_listings fl ON p.provider_id = fl.provider_id\n","GROUP BY\n","    p.location\n","ORDER BY\n","    number_of_listings DESC\n","LIMIT 10;\n","\"\"\"\n","\n","# Execute the query\n","top_locations_df = pd.read_sql(query3, engine)\n","\n","# --- Visualization ---\n","plt.figure(figsize=(12, 7))\n","sns.barplot(x='number_of_listings', y='location', data=top_locations_df, palette='magma')\n","plt.title('Top 10 Locations by Food Listings')\n","plt.xlabel('Number of Listings')\n","plt.ylabel('Location')\n","plt.show()"],"metadata":{"id":"DTHhZ73wp9oQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Analysis 4: How many listings are claimed vs. available?**"],"metadata":{"id":"qVgxotmbq28b"}},{"cell_type":"code","source":["query4 = \"\"\"\n","SELECT\n","    status,\n","    COUNT(listing_id) as count\n","FROM\n","    food_listings\n","GROUP BY\n","    status;\n","\"\"\"\n","\n","status_df = pd.read_sql(query4, engine)\n","\n","# --- Visualization ---\n","plt.figure(figsize=(8, 8))\n","plt.pie(status_df['count'], labels=status_df['status'], autopct='%1.1f%%', startangle=140, colors=['#FF9999','#66B2FF'])\n","plt.title('Proportion of Food Listings by Status (Claimed vs. Available)')\n","plt.ylabel('') # Hides the 'count' label on the y-axis\n","plt.show()"],"metadata":{"id":"-G1gjfb2q4mW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Analysis 5: What is the claim activity by day of the week?**"],"metadata":{"id":"BhUDDZkSrOoQ"}},{"cell_type":"code","source":["# Query to extract the day of the week from the claim_date and count claims\n","# Note: 'W' is for day of week. 0=Sunday, 1=Monday, ...\n","query5 = \"\"\"\n","SELECT\n","    STRFTIME('%w', claim_date) as day_of_week_num,\n","    CASE STRFTIME('%w', claim_date)\n","        WHEN '0' THEN 'Sunday'\n","        WHEN '1' THEN 'Monday'\n","        WHEN '2' THEN 'Tuesday'\n","        WHEN '3' THEN 'Wednesday'\n","        WHEN '4' THEN 'Thursday'\n","        WHEN '5' THEN 'Friday'\n","        ELSE 'Saturday'\n","    END as day_of_week_name,\n","    COUNT(claim_id) as number_of_claims\n","FROM\n","    claims\n","GROUP BY\n","    day_of_week_num\n","ORDER BY\n","    day_of_week_num;\n","\"\"\"\n","claims_by_day_df = pd.read_sql(query5, engine)\n","\n","# --- Visualization ---\n","plt.figure(figsize=(12, 7))\n","sns.barplot(x='day_of_week_name', y='number_of_claims', data=claims_by_day_df, palette='cubehelix')\n","plt.title('Food Claim Activity by Day of the Week')\n","plt.xlabel('Day of the Week')\n","plt.ylabel('Total Number of Claims')\n","plt.show()"],"metadata":{"id":"NpDtaG1BrTFU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Analysis 6: What is the distribution of donation quantities?**"],"metadata":{"id":"m9LCAb7FranW"}},{"cell_type":"code","source":["# Query to get all the quantity data\n","query6 = \"SELECT quantity FROM food_listings;\"\n","quantity_df = pd.read_sql(query6, engine)\n","\n","# --- Visualization ---\n","plt.figure(figsize=(12, 7))\n","# We will filter out extreme outliers for a more readable chart, e.g., quantity < 200\n","sns.histplot(quantity_df[quantity_df['quantity'] < 200]['quantity'], bins=30, kde=True)\n","plt.title('Distribution of Food Donation Quantities')\n","plt.xlabel('Quantity')\n","plt.ylabel('Frequency')\n","plt.show()"],"metadata":{"id":"e02V_RmZrdSq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Analysis 7: Heatmap of Popular Food Items by Day of Week**"],"metadata":{"id":"YmFGUbotrkfh"}},{"cell_type":"code","source":["# A more complex query to join tables and group by two variables\n","query7 = \"\"\"\n","SELECT\n","    fl.food_item,\n","    CASE STRFTIME('%w', c.claim_date)\n","        WHEN '0' THEN 'Sun'\n","        WHEN '1' THEN 'Mon'\n","        WHEN '2' THEN 'Tue'\n","        WHEN '3' THEN 'Wed'\n","        WHEN '4' THEN 'Thu'\n","        WHEN '5' THEN 'Fri'\n","        ELSE 'Sat'\n","    END as day_of_week,\n","    COUNT(c.claim_id) as claim_count\n","FROM\n","    claims c\n","JOIN\n","    food_listings fl ON c.listing_id = fl.listing_id\n","GROUP BY\n","    fl.food_item, day_of_week\n","\"\"\"\n","heatmap_df = pd.read_sql(query7, engine)\n","\n","# We need to pivot the data to create a matrix for the heatmap\n","# We'll focus on the top 10 most claimed food items for clarity\n","top_10_foods = heatmap_df.groupby('food_item')['claim_count'].sum().nlargest(10).index\n","heatmap_df_filtered = heatmap_df[heatmap_df['food_item'].isin(top_10_foods)]\n","heatmap_pivot = heatmap_df_filtered.pivot_table(index='food_item', columns='day_of_week', values='claim_count', fill_value=0)\n","\n","# Reorder columns for logical day progression\n","day_order = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n","heatmap_pivot = heatmap_pivot.reindex(columns=day_order)\n","\n","\n","# --- Visualization ---\n","plt.figure(figsize=(14, 8))\n","sns.heatmap(heatmap_pivot, annot=True, fmt=\"f\", cmap=\"YlGnBu\", linewidths=.5)\n","plt.title('Heatmap of Claim Frequency: Food Item vs. Day of the Week')\n","plt.xlabel('Day of the Week')\n","plt.ylabel('Food Item')\n","plt.show()"],"metadata":{"id":"ZxILTQgHrl3I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#***3.APPLICATION DEVELOPMENT:-***"],"metadata":{"id":"SsiRvKk_s-4w"}},{"cell_type":"markdown","source":["**-Install Streamlit and pyngrok**"],"metadata":{"id":"9pn-qQbjtJhr"}},{"cell_type":"code","source":["!pip install streamlit pyngrok sqlalchemy pandas"],"metadata":{"id":"8KLsvSS8tPq8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**-Create a python file for streamlit app**"],"metadata":{"id":"ZflrF1YYtEmF"}},{"cell_type":"code","source":["# %%writefile app.py\n","# import streamlit as st\n","# import pandas as pd\n","# from sqlalchemy import create_engine, text\n","\n","# # --- Database Connection ---\n","# # Use the same path to your SQLite database file as before\n","# db_path = '/content/drive/My Drive/Colab Notebooks/food_wastage.db'\n","# engine = create_engine(f'sqlite:///{db_path}')\n","\n","# # --- Page Configuration ---\n","# st.set_page_config(\n","#     page_title=\"Food Wastage Management Dashboard\",\n","#     page_icon=\"🍔\",\n","#     layout=\"wide\"\n","# )\n","\n","# # --- Main App Layout ---\n","# st.title(\"Local Food Wastage Management System\")\n","# st.write(\"This dashboard helps manage and analyze food donation data.\")\n","\n","\n","# # --- Section 1: Browse Raw Data ---\n","# st.header(\"Browse Raw Data Tables\")\n","# selected_table = st.selectbox(\"Choose a table to view\", [\"providers\", \"receivers\", \"food_listings\", \"claims\"])\n","\n","# if selected_table:\n","#     try:\n","#         query = f\"SELECT * FROM {selected_table};\"\n","#         df = pd.read_sql(query, engine)\n","#         st.dataframe(df)\n","#     except Exception as e:\n","#         st.error(f\"An error occurred: {e}\")\n","\n","\n","# # --- Section 2: Data Analysis ---\n","# st.header(\"Data Analysis and Insights\")\n","\n","# # Let's add the \"Top 10 Most Active Providers\" chart from our analysis\n","# st.subheader(\"Top 10 Most Active Food Providers\")\n","# query_top_providers = \"\"\"\n","#     SELECT\n","#         p.provider_name,\n","#         COUNT(fl.listing_id) AS total_listings\n","#     FROM\n","#         providers p\n","#     JOIN\n","#         food_listings fl ON p.provider_id = fl.provider_id\n","#     GROUP BY\n","#         p.provider_name\n","#     ORDER BY\n","#         total_listings DESC\n","#     LIMIT 10;\n","# \"\"\"\n","# try:\n","#     top_providers_df = pd.read_sql(query_top_providers, engine)\n","\n","#     # Using st.bar_chart which is simple and effective\n","#     # The dataframe needs to have the label column set as the index\n","#     st.bar_chart(top_providers_df.set_index('provider_name'))\n","\n","# except Exception as e:\n","#     st.error(f\"An error occurred while generating the chart: {e}\")"],"metadata":{"id":"GDyQkL3Str7a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Run the App and Launch ngrok**"],"metadata":{"id":"EJT_fwUcyRzc"}},{"cell_type":"code","source":["# from pyngrok import ngrok\n","\n","# # Terminate any existing ngrok tunnels to avoid errors\n","# ngrok.kill()\n","\n","# # Paste your ngrok authtoken here\n","# NGROK_AUTH_TOKEN = \"30h8lGVso50GSJoQ1OZ3TfAKIl3_2AEHhZukQCnGFBTVfY7fV\"  # <--- PASTE YOUR TOKEN HERE\n","# ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","\n","# # Open a public tunnel to the Streamlit port (8501)\n","# public_url = ngrok.connect(8501)\n","# print(f\" Your Streamlit app is live! URL: {public_url}\")\n","\n","# # Run the Streamlit app in the background\n","# # The '--server.runOnSave true' flag will automatically update the app when you change app.py\n","# !streamlit run app.py --server.runOnSave true &"],"metadata":{"id":"Rok-jb3VyWZt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**-Creating/updating the exsiting python file of streamlit app for CRUD operations**"],"metadata":{"id":"ifnk9hNEyZkZ"}},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","from sqlalchemy import create_engine, text\n","import matplotlib.pyplot as plt\n","\n","# --- Database Connection ---\n","# Use the same path to your SQLite database file\n","db_path = '/content/drive/My Drive/Colab Notebooks/food_wastage.db'\n","engine = create_engine(f'sqlite:///{db_path}')\n","\n","# --- Page Configuration ---\n","st.set_page_config(\n","    page_title=\"Food Wastage Management Dashboard\",\n","    page_icon=\"🍔\",\n","    layout=\"wide\"\n",")\n","\n","# --- Main App Layout ---\n","st.title(\"Local Food Wastage Management System\")\n","st.write(\"This dashboard helps manage and analyze food donation data.\")\n","\n","# --- FEATURE 1: Interactive Filtering via Sidebar ---\n","\n","st.sidebar.header(\"Filter Options\")\n","\n","# Fetch all unique locations from the providers table for the filter\n","with engine.connect() as connection:\n","    locations_query = text(\"SELECT DISTINCT location FROM providers ORDER BY location;\")\n","    locations = connection.execute(locations_query).fetchall()\n","    # The result is a list of tuples, so we extract the first element of each tuple\n","    location_list = [\"All\"] + [location[0] for location in locations]\n","\n","selected_location = st.sidebar.selectbox(\"Filter by Location\", location_list)\n","\n","# --- Display Filtered Food Listings (This is a \"Read\" operation) ---\n","st.header(\"Available Food Listings\")\n","st.write(\"Use the filter on the left to narrow down results.\")\n","\n","# Base query for food listings\n","listings_query = \"\"\"\n","    SELECT\n","        fl.food_item,\n","        fl.quantity,\n","        fl.expiration_date,\n","        p.provider_name,\n","        p.location,\n","        p.contact_info\n","    FROM\n","        food_listings fl\n","    JOIN\n","        providers p ON fl.provider_id = p.provider_id\n","    WHERE\n","        fl.status = 'available'\n","\"\"\"\n","\n","# If a specific location is selected (and not 'All'), add a WHERE clause\n","if selected_location != \"All\":\n","    listings_query += \" AND p.location = :location\"\n","    params = {\"location\": selected_location}\n","    filtered_listings_df = pd.read_sql(text(listings_query), engine, params=params)\n","else:\n","    filtered_listings_df = pd.read_sql(text(listings_query), engine)\n","\n","st.dataframe(filtered_listings_df)\n","\n","# --- FEATURE 2: Add a New Food Listing (This is a \"Create\" operation) ---\n","\n","st.header(\"Add a New Food Donation\")\n","\n","# Fetch provider names for the dropdown menu\n","with engine.connect() as connection:\n","    providers_query = text(\"SELECT provider_id, provider_name FROM providers ORDER BY provider_name;\")\n","    providers = connection.execute(providers_query).fetchall()\n","    provider_dict = {name: pid for pid, name in providers} # Create a name-to-ID dictionary\n","\n","# Use a form to group inputs. The app won't rerun until the 'Submit' button is clicked.\n","with st.form(\"new_listing_form\"):\n","    selected_provider_name = st.selectbox(\"Select the Provider\", options=list(provider_dict.keys()))\n","    food_item = st.text_input(\"Food Item Name\")\n","    quantity = st.number_input(\"Quantity\", min_value=1)\n","    expiration_date = st.date_input(\"Expiration Date\")\n","\n","    submitted = st.form_submit_button(\"Add Listing\")\n","\n","    if submitted:\n","        provider_id = provider_dict[selected_provider_name] # Get the ID from the selected name\n","        insert_query = text(\"\"\"\n","            INSERT INTO food_listings (provider_id, food_item, quantity, expiration_date, status)\n","            VALUES (:provider_id, :food_item, :quantity, :expiration_date, 'available')\n","        \"\"\")\n","\n","        try:\n","            with engine.connect() as connection:\n","                connection.execute(insert_query, {\n","                    \"provider_id\": provider_id,\n","                    \"food_item\": food_item,\n","                    \"quantity\": quantity,\n","                    \"expiration_date\": expiration_date.strftime('%Y-%m-%d')\n","                })\n","                connection.commit()\n","            st.success(\" New listing added successfully!\")\n","            # st.rerun() # Optional: Uncomment to automatically refresh the app state\n","        except Exception as e:\n","            st.error(f\"An error occurred: {e}\")\n","\n","# --- Data Analysis Section ---\n","\n","st.header(\"Data Analysis and Insights\")\n","col1, col2 = st.columns(2)\n","\n","with col1:\n","    st.subheader(\"Top 10 Most Active Providers\")\n","    query_top_providers = text(\"\"\"\n","        SELECT p.provider_name, COUNT(fl.listing_id) AS total_listings\n","        FROM providers p JOIN food_listings fl ON p.provider_id = fl.provider_id\n","        GROUP BY p.provider_name ORDER BY total_listings DESC LIMIT 10;\n","    \"\"\")\n","    top_providers_df = pd.read_sql(query_top_providers, engine)\n","    st.bar_chart(top_providers_df.set_index('provider_name'))\n","\n","with col2:\n","    # --- NEW FEATURE 3: Added Pie Chart Visualization ---\n","    st.subheader(\"Listings by Status\")\n","    query_status = text(\"\"\"\n","        SELECT status, COUNT(listing_id) as count FROM food_listings GROUP BY status;\n","    \"\"\")\n","    status_df = pd.read_sql(query_status, engine)\n","\n","    fig, ax = plt.subplots()\n","    ax.pie(status_df['count'], labels=status_df['status'], autopct='%1.1f%%', startangle=90, colors=['#FF9999','#66B2FF'])\n","    ax.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\n","    st.pyplot(fig)"],"metadata":{"id":"sguxTkPWxDw6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Run the App and Launch ngrok**"],"metadata":{"id":"uMQzkS0Lt1_f"}},{"cell_type":"code","source":["from pyngrok import ngrok\n","\n","# Terminate any existing ngrok tunnels to avoid errors\n","ngrok.kill()\n","\n","# Paste your ngrok authtoken here\n","NGROK_AUTH_TOKEN = \"30h8lGVso50GSJoQ1OZ3TfAKIl3_2AEHhZukQCnGFBTVfY7fV\"  # <--- PASTE YOUR TOKEN HERE\n","ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","\n","# Open a public tunnel to the Streamlit port (8501)\n","public_url = ngrok.connect(8501)\n","print(f\" Your Streamlit app is live! URL: {public_url}\")\n","\n","# Run the Streamlit app in the background\n","# The '--server.runOnSave true' flag will automatically update the app when you change app.py\n","!streamlit run app.py --server.runOnSave true &"],"metadata":{"id":"fvccHfRgt3tF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["This project successfully developed a functional prototype of the Local Food Wastage Management System, proving the concept's viability. By processing raw data into a structured SQLite database and building an interactive Streamlit application, we created a tool that effectively visualizes key trends, allows users to filter available food listings, and implements essential \"Create\" and \"Read\" functionality. The system serves as a robust foundation for a real-world solution, with clear next steps toward implementing full CRUD operations and cloud deployment to actively combat local food waste."],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}